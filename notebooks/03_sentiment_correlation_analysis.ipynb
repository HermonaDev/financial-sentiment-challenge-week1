{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d54bc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TASK 3: SENTIMENT & CORRELATION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "✓ Libraries imported successfully!\n",
      "Analysis Date: 2025-11-22 23:26\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TASK 3: Sentiment Analysis & Correlation with Stock Returns\n",
    "# KAIM Week 1 - Financial Sentiment Challenge\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TASK 3: SENTIMENT & CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n✓ Libraries imported successfully!\")\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb1b5e9",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2898ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOADED:\n",
      "  Total articles: 1,407,328\n",
      "  Date range: 2011-04-27 to 2020-06-11\n",
      "  Unique stocks: 6204\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: Load Data and Perform Sentiment Analysis\n",
    "# =============================================================================\n",
    "\n",
    "# Load news data\n",
    "news_df = pd.read_csv('../data/newsData/raw_analyst_ratings.csv')  # Adjust path if needed\n",
    "\n",
    "# Parse dates\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce')\n",
    "news_df['date_only'] = news_df['date'].dt.date\n",
    "\n",
    "print(\"DATA LOADED:\")\n",
    "print(f\"  Total articles: {len(news_df):,}\")\n",
    "print(f\"  Date range: {news_df['date'].min().date()} to {news_df['date'].max().date()}\")\n",
    "print(f\"  Unique stocks: {news_df['stock'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating sentiment scores...\n",
      "(This may take 1-2 minutes for large datasets)\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis Function\n",
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Calculate sentiment polarity using TextBlob\n",
    "    Returns: float between -1 (negative) and +1 (positive)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return TextBlob(str(text)).sentiment.polarity\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def categorize_sentiment(score):\n",
    "    \"\"\"Categorize sentiment score into Positive/Neutral/Negative\"\"\"\n",
    "    if score > 0.1:\n",
    "        return 'Positive'\n",
    "    elif score < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis\n",
    "print(\"\\nCalculating sentiment scores...\")\n",
    "print(\"(This may take 1-2 minutes for large datasets)\")\n",
    "\n",
    "news_df['sentiment'] = news_df['headline'].apply(get_sentiment)\n",
    "news_df['sentiment_category'] = news_df['sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "print(\"\\n✓ SENTIMENT ANALYSIS COMPLETE!\")\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"SENTIMENT DISTRIBUTION:\")\n",
    "print(\"=\" * 40)\n",
    "print(news_df['sentiment_category'].value_counts())\n",
    "print(f\"\\nSentiment Statistics:\")\n",
    "print(f\"  Mean:   {news_df['sentiment'].mean():.4f}\")\n",
    "print(f\"  Median: {news_df['sentiment'].median():.4f}\")\n",
    "print(f\"  Std:    {news_df['sentiment'].std():.4f}\")\n",
    "print(f\"  Min:    {news_df['sentiment'].min():.4f}\")\n",
    "print(f\"  Max:    {news_df['sentiment'].max():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
